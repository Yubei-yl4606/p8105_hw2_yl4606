p8105\_hw2\_yl4606
================
Yubei Liang
9/28/2020

This is my HW2 solutions.

``` r
library(tidyverse)
library(readxl)
```

# Problem 1

Read and clean the Mr. Trashwheel dataset.

``` r
trash_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )

trash_df
```

    ## # A tibble: 344 x 14
    ##    dumpster month  year date                weight_tons volume_cubic_ya…
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>            <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31               18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74               13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45               15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06               18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71               13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52               14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76               18
    ## # … with 334 more rows, and 8 more variables: plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <int>,
    ## #   homes_powered <dbl>

Read and clean the 2017 and 2018 precipitation datasets.

``` r
precipitation_2017_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1,
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)

precipitation_2018_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1,
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)
```

Combine two precipitation datasets.

``` r
precip_df = 
  bind_rows( precipitation_2017_df, precipitation_2018_df)

precip_df
```

    ## # A tibble: 24 x 3
    ##     year month total
    ##    <dbl> <dbl> <dbl>
    ##  1  2017     1  2.34
    ##  2  2017     2  1.46
    ##  3  2017     3  3.57
    ##  4  2017     4  3.99
    ##  5  2017     5  5.64
    ##  6  2017     6  1.4 
    ##  7  2017     7  7.09
    ##  8  2017     8  4.44
    ##  9  2017     9  1.95
    ## 10  2017    10  0   
    ## # … with 14 more rows

For Mr. Wheel Trsh data frame, there are 344 times of dumpster
obervation. Key variables include dumpster, month, year, date,
weight\_tons, volume\_cubic\_yards, plastic\_bottles, polystyrene,
cigarette\_butts, glass\_bottles, grocery\_bags, chip\_bags,
sports\_balls, homes\_powered . For precipitation data frame, there are
24 times of obervation. Key variables include year, month, total . The
total precipitation for 2018 is 70.33. The median number of sports balls
in a dumpster in 2017 is 8.

# Problem 2

Read and clean the NYC subway dataset.

``` r
raw_nyc_subway_df = 
  read_csv(
  "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  ) %>%
  janitor::clean_names() 

new_nyc_subway_df = 
  raw_nyc_subway_df %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE),
         route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11),
         vending = recode(vending, "YES" = TRUE, "NO" = FALSE))

new_nyc_subway_df
```

    ## # A tibble: 1,868 x 19
    ##    line  station_name station_latitude station_longitu… route1 route2 route3
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Av… 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ##  2 4 Av… 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ##  3 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  4 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  5 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  6 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  7 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  8 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  9 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ## 10 4 Av… 53rd St                  40.6            -74.0 R      <NA>   <NA>  
    ## # … with 1,858 more rows, and 12 more variables: route4 <chr>, route5 <chr>,
    ## #   route6 <chr>, route7 <chr>, route8 <chr>, route9 <chr>, route10 <chr>,
    ## #   route11 <chr>, entrance_type <chr>, entry <lgl>, vending <lgl>, ada <lgl>

The raw NYC subway dataset include variables division, line,
station\_name, station\_latitude, station\_longitude, route1, route2,
route3, route4, route5, route6, route7, route8, route9, route10,
route11, entrance\_type, entry, exit\_only, vending, staffing,
staff\_hours, ada, ada\_notes, free\_crossover, north\_south\_street,
east\_west\_street, corner, entrance\_latitude, entrance\_longitude,
station\_location, entrance\_location. My cleaning process include
reading data, cleaning variable names using janitor package, selecting
key variables (line, station\_name, station\_latitude,
station\_longitude, route1, route2, route3, route4, route5, route6,
route7, route8, route9, route10, route11, entrance\_type, entry,
vending, ada). Finally, I use recode() function to convert variable
‘entry’ from character to logical, variable ‘vending’ from character
to logical, and all variables with prefix ‘route’ are converted to the
same class character for furthur explore. NAs are not removed because
the NAs here are informative with regard to routes. The dimention of the
resulting dataset is 1868 rows by 19 columns. No, the data looks not
tidy for me. For variables and values start with ‘route’, although they
are human readable, it is inconvenient to use computer language to fetch
informations.

There are 465 distinct subway stations, 84 of them are ADA compliant.
0.3770492 fraction of station entrances / exits without vending allow
entrance.

``` r
reformat_nyc_subway_df<-
  new_nyc_subway_df%>%
  pivot_longer(
    route1 : route11,
    names_to = "route_number",
    values_to = "route_name"
    ) %>%
  drop_na(route_name)

reformat_nyc_subway_df
```

    ## # A tibble: 4,270 x 10
    ##    line  station_name station_latitude station_longitu… entrance_type entry
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>         <lgl>
    ##  1 4 Av… 25th St                  40.7            -74.0 Stair         TRUE 
    ##  2 4 Av… 25th St                  40.7            -74.0 Stair         TRUE 
    ##  3 4 Av… 36th St                  40.7            -74.0 Stair         TRUE 
    ##  4 4 Av… 36th St                  40.7            -74.0 Stair         TRUE 
    ##  5 4 Av… 36th St                  40.7            -74.0 Stair         TRUE 
    ##  6 4 Av… 36th St                  40.7            -74.0 Stair         TRUE 
    ##  7 4 Av… 36th St                  40.7            -74.0 Stair         TRUE 
    ##  8 4 Av… 36th St                  40.7            -74.0 Stair         TRUE 
    ##  9 4 Av… 45th St                  40.6            -74.0 Stair         TRUE 
    ## 10 4 Av… 45th St                  40.6            -74.0 Stair         TRUE 
    ## # … with 4,260 more rows, and 4 more variables: vending <lgl>, ada <lgl>,
    ## #   route_number <chr>, route_name <chr>

After reformating data, 60 distinct stations serve the A train. 17 of
them are ADA compliant.

# Problem 3

Read and clean the data in pols-month.csv.

``` r
# create a tibble to convert month number
month_df = 
  tibble(
    month = 1:12,
    month_abbr = month.abb,
    month_name = month.name
  )

pols_month_df = 
  read_csv(
    "./Data/fivethirtyeight_datasets/pols-month.csv"
  ) %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(month = as.integer(month)) %>% 
  left_join(month_df, by = "month") %>% 
  select(-c(month, month_abbr)) %>% 
  relocate(year, month_name) %>% 
  rename(
    month = month_name,
    gop = prez_gop,
    dem = prez_dem
  ) %>% 
  pivot_longer(
    c(gop, dem),
    names_to = "president",
    values_to = "president_num",
  ) %>%
  filter( president_num == 1) %>% 
  select(-c(president_num, day)) %>% 
  relocate(year, month, president)

pols_month_df
```

    ## # A tibble: 817 x 9
    ##    year  month     president gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem
    ##    <chr> <chr>     <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1 1947  January   dem            23      51     253      23      45     198
    ##  2 1947  February  dem            23      51     253      23      45     198
    ##  3 1947  March     dem            23      51     253      23      45     198
    ##  4 1947  April     dem            23      51     253      23      45     198
    ##  5 1947  May       dem            23      51     253      23      45     198
    ##  6 1947  June      dem            23      51     253      23      45     198
    ##  7 1947  July      dem            23      51     253      23      45     198
    ##  8 1947  August    dem            23      51     253      23      45     198
    ##  9 1947  September dem            23      51     253      23      45     198
    ## 10 1947  October   dem            23      51     253      23      45     198
    ## # … with 807 more rows

Read and clean data in snp.csv.

``` r
snp_df =
  read_csv(
    "./Data/fivethirtyeight_datasets/snp.csv"
  ) %>% 
  separate(date, into = c("month", "day", "year"), sep = "/") %>% 
  mutate(month = as.integer(month)) %>%
  arrange(year, month, day) %>% 
  left_join(month_df, by = "month") %>% 
  select(-c(month, day, month_abbr)) %>% 
  relocate(year, month_name) %>% 
  rename(
    month = month_name
  ) 

snp_df
```

    ## # A tibble: 787 x 3
    ##    year  month     close
    ##    <chr> <chr>     <dbl>
    ##  1 1950  January    17.0
    ##  2 1950  February   17.2
    ##  3 1950  March      17.3
    ##  4 1950  April      18.0
    ##  5 1950  May        18.8
    ##  6 1950  June       17.7
    ##  7 1950  July       17.8
    ##  8 1950  August     18.4
    ##  9 1950  September  19.5
    ## 10 1950  October    19.5
    ## # … with 777 more rows

Read and clean unemployment data.

``` r
unemployment_df = 
  read_csv(
    "./Data/fivethirtyeight_datasets/unemployment.csv"
  ) %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month_abbr",
    values_to = "unemployment_pct"
  ) %>% 
  drop_na(unemployment_pct) %>% 
  left_join(month_df, by = "month_abbr") %>% 
  mutate(year = as.character(Year)) %>% 
  arrange(year, month) %>% 
  select(-c(month, month_abbr, Year)) %>% 
  rename(
    month = month_name,
  ) %>% 
  relocate(year,month)

unemployment_df
```

    ## # A tibble: 810 x 3
    ##    year  month     unemployment_pct
    ##    <chr> <chr>                <dbl>
    ##  1 1948  January                3.4
    ##  2 1948  February               3.8
    ##  3 1948  March                  4  
    ##  4 1948  April                  3.9
    ##  5 1948  May                    3.5
    ##  6 1948  June                   3.6
    ##  7 1948  July                   3.6
    ##  8 1948  August                 3.9
    ##  9 1948  September              3.8
    ## 10 1948  October                3.7
    ## # … with 800 more rows

Merging the three data frames.

``` r
result_data = 
  full_join(pols_month_df, snp_df, by = c("year", "month")) %>% 
  full_join(unemployment_df, by = c("year", "month")) %>% 
  arrange(year)

result_data
```

    ## # A tibble: 823 x 11
    ##    year  month president gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem close
    ##    <chr> <chr> <chr>       <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>
    ##  1 1947  Janu… dem            23      51     253      23      45     198    NA
    ##  2 1947  Febr… dem            23      51     253      23      45     198    NA
    ##  3 1947  March dem            23      51     253      23      45     198    NA
    ##  4 1947  April dem            23      51     253      23      45     198    NA
    ##  5 1947  May   dem            23      51     253      23      45     198    NA
    ##  6 1947  June  dem            23      51     253      23      45     198    NA
    ##  7 1947  July  dem            23      51     253      23      45     198    NA
    ##  8 1947  Augu… dem            23      51     253      23      45     198    NA
    ##  9 1947  Sept… dem            23      51     253      23      45     198    NA
    ## 10 1947  Octo… dem            23      51     253      23      45     198    NA
    ## # … with 813 more rows, and 1 more variable: unemployment_pct <dbl>

‘pols\_month\_df’ dataset gives the number of national politicians who
are democratic or republican at any given time. ‘snp\_df’ dataset gives
Standard & Poor’s stock market index (S\&P), often used as a
representative measure of stock market as a whole. ‘unemployment\_df’
dataset gives percentage of unemployment. All three datasets provide
values per month in a year range 1947, 2015. The resulting dimension is
823 rows by 11 columns. The key variables include year, month,
president, gov\_gop, sen\_gop, rep\_gop, gov\_dem, sen\_dem, rep\_dem,
close, unemployment\_pct.
