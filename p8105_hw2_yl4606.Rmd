---
title: "p8105_hw2_yl4606"
author: "Yubei Liang"
date: "9/28/2020"
output: github_document
---

This is my HW2 solutions.

```{r setup, message=FALSE}
library(tidyverse)
library(readxl)
```


# Problem 1

Read and clean the Mr. Trashwheel dataset.

```{r}
trash_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read and clean the 2017 and 2018 precipitation datasets.

```{r}
precipitation_2017_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1,
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)

precipitation_2018_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1,
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)
```

Combine two precipitation datasets.

```{r}
precip_df = 
  bind_rows( precipitation_2017_df, precipitation_2018_df)
```

For Mr. Wheel Trsh data frame, there are `r nrow(trash_df)` times of dumpster obervation. Key variables include `r names(trash_df)` . For precipitation data frame, there are `r nrow(precip_df)` times of obervation. Key variables include `r names(precip_df)` . The total precipitation for 2018 is `r sum(pull(precipitation_2018_df, total))`. The median number of sports balls in a dumpster in 2017 is `r sb<-trash_df %>% filter(year==2017)` `r median(pull(sb,sports_balls))`.

```{r}
rm(sb, precipitation_2018_df, precipitation_2017_df)
```



# Problem 2

Read and clean the NYC subway dataset.

```{r message=FALSE}
raw_nyc_subway_df = 
  read_csv(
  "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  ) %>%
  janitor::clean_names() 

new_nyc_subway_df = 
  raw_nyc_subway_df %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE),
         route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11),
         vending = recode(vending, "YES" = TRUE, "NO" = FALSE))
```

The raw NYC subway dataset include variables `r names(raw_nyc_subway_df)`. My cleaning process include reading data, cleaning variable names using janitor package, selecting key variables (`r names(new_nyc_subway_df)`). Finally, I use recode() function to convert variable 'entry' from character to logical, variable 'vending' from character to logical, and all variables with prefix 'route' are converted to the same class character for furthur explore. NAs are not removed because the NAs here are informative with regard to routes. The dimention of the resulting dataset is `r nrow(new_nyc_subway_df)` rows by `r ncol(new_nyc_subway_df)` columns. No, the data looks not tidy for me. For variables and values start with 'route', although they are human readable, it is inconvenient to use computer language to fetch informations. 

There are `r nrow(distinct(new_nyc_subway_df, line, station_name))` distinct subway stations, `r new_nyc_subway_df%>%distinct(line, station_name, ada)%>%filter(ada==TRUE)%>%nrow()` of them are ADA compliant. `r nrow(new_nyc_subway_df %>% filter(entry == TRUE & vending == FALSE))/nrow(new_nyc_subway_df %>% filter(vending == FALSE))` fraction of station entrances / exits without vending allow entrance.


```{r reformat}
reformat_nyc_subway_df<-
  new_nyc_subway_df%>%
  pivot_longer(
    route1 : route11,
    names_to = "route_number",
    values_to = "route_name"
    ) %>%
  drop_na(route_name)
```

After reformating data, `r reformat_nyc_subway_df %>% filter(route_name == "A") %>% distinct(line, station_name) %>% nrow()` distinct stations serve the A train. `r reformat_nyc_subway_df %>% filter(route_name == "A" & ada == T) %>% distinct(line, station_name) %>% nrow()` of them are ADA compliant.



# Problem 3

Read and clean the data in pols-month.csv.

```{r message=FALSE}
# create a tibble to convert month number
month_df = 
  tibble(
    month = 1:12,
    month_abbr = month.abb,
    month_name = month.name
  )

pols_month_df = 
  read_csv(
    "./Data/fivethirtyeight_datasets/pols-month.csv"
  ) %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(month = as.integer(month)) %>% 
  left_join(month_df, by = "month") %>% 
  select(-c(month, month_abbr)) %>% 
  relocate(year, month_name) %>% 
  rename(
    month = month_name,
    gop = prez_gop,
    dem = prez_dem
  ) %>% 
  pivot_longer(
    c(gop, dem),
    names_to = "president",
    values_to = "president_num",
  ) %>%
  filter( president_num == 1) %>% 
  select(-c(president_num, day)) %>% 
  relocate(year, month, president)
```


Read and clean data in snp.csv.

```{r message=FALSE}
snp_df =
  read_csv(
    "./Data/fivethirtyeight_datasets/snp.csv"
  ) %>% 
  separate(date, into = c("month", "day", "year"), sep = "/") %>% 
  mutate(month = as.integer(month)) %>%
  arrange(year, month, day) %>% 
  left_join(month_df, by = "month") %>% 
  select(-c(month, day, month_abbr)) %>% 
  relocate(year, month_name) %>% 
  rename(
    month = month_name
  ) 
```


Read and clean unemployment data.

```{r message=FALSE}
unemployment_df = 
  read_csv(
    "./Data/fivethirtyeight_datasets/unemployment.csv"
  ) %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month_abbr",
    values_to = "unemployment_pct"
  ) %>% 
  drop_na(unemployment_pct) %>% 
  left_join(month_df, by = "month_abbr") %>% 
  mutate(year = as.character(Year)) %>% 
  arrange(year, month) %>% 
  select(-c(month, month_abbr, Year)) %>% 
  rename(
    month = month_name,
  ) %>% 
  relocate(year,month)
```


Merging the three data frames.

```{r message=FALSE}
result_data = 
  full_join(pols_month_df, snp_df, by = c("year", "month")) %>% 
  full_join(unemployment_df, by = c("year", "month")) %>% 
  arrange(year)
```

'pols_month_df' dataset gives the number of national politicians who are democratic or republican at any given time. 'snp_df' dataset gives Standard & Poorâ€™s stock market index (S&P), often used as a representative measure of stock market as a whole. 'unemployment_df' dataset gives percentage of unemployment. All three datasets provide values per month in a year range `r range(as.numeric(pull(result_data, year)))`. The resulting dimension is `r nrow(result_data)` rows by `r ncol(result_data)` columns. The key variables include `r names(result_data)`.


